# PromptFence
A semantic guardrail for healthcare LLMs. This project uses contrastive fine-tuning to train a BERT model that semantically separates harmful and safe prompts. On a 58k prompt dataset, this custom model achieves 92% accuracy and a 0.97 AUC-ROC, decisively outperforming 5 standard baseline models.
